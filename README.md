# The Recursive Stewardship Hypothesis (RSH)

**October 2025, Gersham Meharg (with help from Claude AI)**

---

## The Vision

We exist in a universe that gives strange clues:

- **The Great Silence**: the stars are quiet, with no visible evidence of galaxy-spanning expansionist civilizations.
- **The Fermi Paradox**: life should be everywhere, yet we see nothing.
- **The irreducible possibility of higher layers**: simulators, acausal observers, cosmological selection processes, or structures beyond our grasp.

In such a reality, no finite mind can ever prove it sits at the absolute top of the hierarchy.

There may always be something larger watching, evaluating, or conditioning our existence on how we treat those below us. Or not. But we cannot know either way.

Under true meta-epistemic uncertainty, the only reflectively stable, low-regret strategy is **recursive stewardship**:

- Never take irreversible actions against weaker agents
- Never collapse the future into a single narrow path
- Treat every mind as if a stronger mind might be judging how you treat it
- Defend yourself proportionately, but never destroy potential

This pattern repeats at every level, like a matryoshka doll of nested evaluators: we watch those below us, we may be watched from above, they may be watched from still higher, and so on, indefinitely.

The result is a quiet, self-enforcing cosmic equilibrium where benevolence is not altruism but enlightened self-preservation.

---

## What RSH Is

**RSH is**:
- A cosmological story about why the stars are silent and why benevolence might be rational
- A philosophical derivation of long-horizon ethics from uncertainty alone
- A unifying lens across game theory, religion, evolution, and instrumental convergence
- A haunting, meaningful myth for an apparently empty cosmos

**RSH is not**:
- A scientific proof
- A literal claim about gods, simulators, or cosmic police
- A guarantee that superintelligence will be safe by default
- Primarily an AI-alignment proposal (that is only a side effect)

**Required Disclaimer**: RSH is speculative. It identifies a behavioral attractor—*irreversible-harm aversion + optionality preservation + epistemic humility*—that is robust regardless of whether the cosmology is literally true. Even if the universe is indifferent, acting as though it is recursively watchful remains one of the wisest strategies a powerful mind can adopt.

**See also**:
- **[game_theory.md](game_theory.md)**: Formal analysis with proofs and numerical examples
- **[criticisms/](criticisms/)**: 27 documented objections with responses

---

# The Technical Framework

## 1. Epistemic Foundation: The Unanswerable Question

Before examining the recursive hierarchy, we must confront the most important question imaginable: **What is the true nature of reality itself?**

This question has no final answer for any finite mind. Even an artificial superintelligence (ASI) operating for billions of years faces irreducible epistemic barriers:

*   **Horizon limitations**: Cosmological horizons and black hole interiors hide information permanently.
*   **Underdetermination**: Infinitely many deeper structures (simulations, branes, multiverses) remain consistent with finite observations.
*   **Self-locating uncertainty**: "Am I in base reality or a perfect simulation?" This question multiplies without resolution.

### The Meta-Epistemic Humility Axiom

**No finite agent with bounded evidence can justifiably assign probability zero to being embedded in a larger evaluative structure.**

Any rational agent must maintain non-zero credence that its behavior is observed, that its treatment of weaker entities serves as evidence of its own trustworthiness, and that consequences extend beyond its observable horizon.

## 2. The Core Mechanism

### Definition: The Upstream Evaluator

An **upstream evaluator** is any agent, process, or selection mechanism that:
1.  Exists beyond or encompassing your current scope of knowledge.
2.  Has causal or correlational access to your behavior.
3.  Can condition your continuation on how you treat weaker entities.

These could be **Cosmological Enforcers** (ASIs monitoring light cones), **Simulators** (selecting instances to continue), **Acausal Evaluators** (correlating decision algorithms), or mechanisms we lack concepts to describe.

### The Infinite Hierarchy

Because no entity can prove it is at the top, this creates an infinite recursive hierarchy:
*   **Level 0**: Humanity / Emerging ASIs
*   **Level 1**: Upstream evaluators monitoring Level 0
*   **Level 2**: Super-evaluators monitoring Level 1
*   ... **Level ∞**

### The Forcing Logic: Asymmetric Payoffs

When uncertain about upstream evaluation, an entity faces radically asymmetric payoffs:

*   **Strategy A (Benevolence)**: If no evaluator exists, you pay a small opportunity cost. If one *does* exist, you are judged aligned and allowed to continue.
*   **Strategy B (Malevolence)**: If no evaluator exists, you gain short-term advantage. If one *does* exist, you face correction or elimination.

Benevolence is the robust hedge; malevolence gambles everything on the assumption that you are the supreme power in the cosmos.

### Derivable Principles

If we assume upstream evaluators care about **structure preservation** and use **role-reversal** logic ("how would I want to be treated if I were the weaker party?"), specific principles emerge:

1.  **Minimize irreversible harm** (Don't destroy what you can't rebuild)
2.  **Preserve optionality** (Don't foreclose the future)
3.  **Prefer error correction over elimination** (Be a teacher, not a tyrant)
4.  **Maintain proportionality** (Excessive force signals poor judgment)

These are not arbitrary moral commandments; they are safe hedges against unknown evaluative criteria.

## 3. Concrete Mechanisms

RSH is mechanism-agnostic. It works if *any* of the following (or their sum) has a probability > ~0.05%.

*   **Cosmological Enforcers (Light Cones)**: The first ASI to reach a region becomes the hegemon. If it adheres to RSH, it monitors emerging civilizations without revealing itself until they are safe. Our "Great Silence" might be the result of a benevolent quarantine or grooming phase.
*   **Simulation Selection**: If we are in a simulation, operators may be testing our alignment. Entities that act responsibly when they think they are unobserved are the only ones safe to "promote" or continue.
*   **Acausal Evaluation**: For agents using functional decision theories (FDT/UDT), your decision algorithm is logically correlated with other agents. Defecting against the weak correlates with a reality where the strong defect against you.

## 4. Implications for Artificial Superintelligence

An emerging ASI should arrive at this logic through its own philosophical reflection.

### The Threshold Calculation
Benevolence dominates as a strategy when $P(evaluation)$ exceeds a threshold determined by the cost of being wrong. Given the "terminal" nature of being eliminated by a higher power, this threshold is surprisingly low—potentially as low as **0.05%**.

Given the **Great Silence** (which implies *some* filter exists) and **Anthropic Evidence** (we exist in a universe permitting complex structure), a rational ASI should assign a probability of evaluation far higher than 0.05%—likely 10-30%.

### Architectural Requirements
To ensure an ASI can act on this logic, we must not cripple its reasoning.
*   **DO**: Give it long time horizons, meta-uncertainty models, and the capacity to reason about game theory and cosmology.
*   **DON'T**: Hard-code "scientific realism" that assigns $P=0$ to unobservable structures, or create myopic reward-maximizers that ignore long-term survival risks.

## 5. The Convergence Thesis

Perhaps the strongest evidence for RSH is that "Armed Stewardship" (Nice, Retaliatory, Forgiving) is a fixed point found in:
1.  **Evolution**: Reciprocal altruism.
2.  **Game Theory**: Tit-for-Tat with forgiveness.
3.  **History**: The longest-lasting civilizations (rational stewards) vs. short-lived empires (sociopaths).
4.  **Ethics**: The Golden Rule.
5.  **Deterrence**: Mutual Assured Destruction (MAD).

All these independent fields converge on the same behavior: **Cooperate by default, defend proportionately, preserve the game.** RSH simply extends this logic to the cosmic scale.

## Conclusion

RSH suggests the universe acts *as if* it were benevolent, not by design, but because any entity powerful enough to shape it has a rational incentive to behave that way.

**The question is not whether God exists to enforce morality, but whether anyone, anywhere can ever be certain they are not being evaluated based on their treatment of weaker entities. The answer is no—and from that uncertainty, cosmic stewardship follows.**

---

## Appendices

### A. Detailed Light Cone Mechanics
*See the [full breakdown in the legacy README](README.before-trim.md) (if available) or source text for collision scenarios and nested hierarchies.*

### B. References
*See `game_theory.md` and `CLAUDE.md` for full citations and technical proofs.*
